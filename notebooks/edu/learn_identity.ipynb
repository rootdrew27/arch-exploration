{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop \n",
    "\n",
    "def train(net, X, Y, loss_f, opt, iters=100, pp=10):\n",
    "\n",
    "    if hasattr(net, 'iters_trained_for'):\n",
    "        net.train(True)\n",
    "\n",
    "        for i in range(iters):\n",
    "\n",
    "            y = net(X)\n",
    "            l = loss_f(y, Y)\n",
    "            l.backward()\n",
    "\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            if (i + 1) % pp == 0: print(f'Loss at epoch {i + 1}: {l}\\n')\n",
    "\n",
    "            if l == 0: break\n",
    "\n",
    "        net.iters_trained_for += iters\n",
    "        return l\n",
    "    \n",
    "    else: print('Error! Make sure the network has an \\'iters_trained_for\\' attribute'); return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SadNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.iters_trained_for = 0\n",
    "        \n",
    "        self.lin = nn.Linear(10, 10, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.lin(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(118)\n",
    "\n",
    "X = torch.randn(20, 1, 10)\n",
    "Y = X \n",
    "\n",
    "sadNet = SadNet()\n",
    "loss_f = nn.MSELoss()\n",
    "opt = optim.Adadelta(sadNet.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 100: 4.583590885315347e-12\n",
      "\n",
      "Loss at epoch 200: 4.3782573053152696e-12\n",
      "\n",
      "Loss at epoch 300: 4.289868373724692e-12\n",
      "\n",
      "Loss at epoch 400: 4.210805315540966e-12\n",
      "\n",
      "Loss at epoch 500: 4.106787392793576e-12\n",
      "\n",
      "Loss at epoch 600: 4.080192780864245e-12\n",
      "\n",
      "Loss at epoch 700: 4.067870606333512e-12\n",
      "\n",
      "Loss at epoch 800: 4.078000524071479e-12\n",
      "\n",
      "Loss at epoch 900: 4.0424356570478714e-12\n",
      "\n",
      "Loss at epoch 1000: 4.061495497559298e-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = train(sadNet, X, Y, loss_f, opt, iters=1000, pp=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadNet.iters_trained_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.iters_trained_for = 0\n",
    "        \n",
    "        self.lin = nn.Linear(10, 10, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.lin(X) + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(118)\n",
    "\n",
    "# X1 = torch.randn(20, 1, 10)\n",
    "# Y1 = X1 \n",
    "\n",
    "mResNet = MicroResNet()\n",
    "loss_f = nn.MSELoss()\n",
    "opt1 = optim.Adam(mResNet.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 100: 0.0006777478265576065\n",
      "\n",
      "Loss at epoch 200: 0.0001802691404009238\n",
      "\n",
      "Loss at epoch 300: 0.0008175352704711258\n",
      "\n",
      "Loss at epoch 400: 1.369751407764852e-05\n",
      "\n",
      "Loss at epoch 500: 8.7250693468377e-05\n",
      "\n",
      "Loss at epoch 600: 0.0003115302824880928\n",
      "\n",
      "Loss at epoch 700: 0.00036252086283639073\n",
      "\n",
      "Loss at epoch 800: 2.193046748288907e-05\n",
      "\n",
      "Loss at epoch 900: 9.196352266371832e-07\n",
      "\n",
      "Loss at epoch 1000: 0.00045749536366201937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss1 = train(mResNet, X, Y, loss_f, opt1, iters=1000, pp=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Arch Exploration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
